name: EKS Infrastructure and Application Deployment
description: Complete CI/CD pipeline for EKS cluster deployment and application management

# Pipeline metadata
metadata:
  default_tags: "kubernetes,eks,terraform,microservices"
  
# Environment variables
env:
  AWS_REGION: "us-east-1"
  EKS_CLUSTER_NAME: "eks_cluster"
  ECR_REPOSITORY: "microservices-demo"
  TERRAFORM_VERSION: "1.5.0"
  KUBECTL_VERSION: "1.27.0"
  HELM_VERSION: "3.12.0"

# Workflow definition
workflow:
  # Triggers
  on:
    - push:
        branches: [main, develop, feature/*]
    - pull_request:
        branches: [main]
    - schedule:
        cron: "0 2 * * *"  # Daily at 2 AM for maintenance
    - manual: {}

  # Global pipeline parameters
  parameters:
    - name: environment
      type: choice
      description: "Target environment"
      default: "staging"
      values: ["staging", "production"]
    - name: deploy_apps
      type: boolean
      description: "Deploy applications after infrastructure"
      default: true
    - name: run_tests
      type: boolean
      description: "Run integration tests"
      default: true
    - name: terraform_action
      type: choice
      description: "Terraform action to perform"
      default: "apply"
      values: ["plan", "apply", "destroy"]

  # Prerequisites job
  prerequisites:
    description: "Check prerequisites and setup environment"
    stage: validate
    requirements:
      - model: linux
        os: ubuntu
        memory: 1024
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: install-tools
        run: |
          # Install AWS CLI
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install
          
          # Install Terraform
          wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
          sudo apt update && sudo apt install terraform
          
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/v$KUBECTL_VERSION/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          # Install Helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          
          # Verify installations
          aws --version
          terraform --version
          kubectl version --client
          helm version
          
      - name: configure-aws
        run: |
          aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
          aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
          aws configure set region $AWS_REGION
          aws sts get-caller-identity
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"

  # Security scanning job
  security-scan:
    description: "Perform security scans on code and infrastructure"
    stage: validate
    depends_on: [prerequisites]
    requirements:
      - model: linux
        os: ubuntu
        memory: 2048
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: terraform-security-scan
        run: |
          # Install Checkov
          pip3 install checkov
          
          # Scan Terraform files
          checkov -d . --framework terraform --output json --output-file checkov-report.json || true
          checkov -d . --framework terraform --output cli
          
          # Install and run Trivy
          sudo apt-get update
          sudo apt-get install wget apt-transport-https gnupg lsb-release
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
          echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
          sudo apt-get update
          sudo apt-get install trivy
          
          # Scan filesystem
          trivy fs --format json --output trivy-report.json .
          trivy fs .
          
      - name: upload-security-reports
        uses: actions/artifactUpload
        with:
          name: security-reports
          path: |
            checkov-report.json
            trivy-report.json

  # Terraform plan job
  terraform-plan:
    description: "Create Terraform execution plan"
    stage: plan
    depends_on: [security-scan]
    requirements:
      - model: linux
        os: ubuntu
        memory: 1024
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: setup-terraform
        run: |
          terraform --version
          
      - name: terraform-init
        run: |
          terraform init
          
      - name: terraform-validate
        run: |
          terraform validate
          
      - name: terraform-plan
        run: |
          terraform plan -out=tfplan
          terraform show -json tfplan > tfplan.json
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"
          
      - name: upload-terraform-plan
        uses: actions/artifactUpload
        with:
          name: terraform-plan
          path: |
            tfplan
            tfplan.json

  # Infrastructure deployment job
  terraform-apply:
    description: "Deploy EKS infrastructure with Terraform"
    stage: deploy-infra
    depends_on: [terraform-plan]
    requirements:
      - model: linux
        os: ubuntu
        memory: 2048
    conditions:
      - type: manual
        when: "{{.workflow.parameters.terraform_action}} == 'apply'"
      - type: branch
        when: "{{.git.branch}} == 'main'"
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: download-terraform-plan
        uses: actions/artifactDownload
        with:
          name: terraform-plan
          
      - name: terraform-init
        run: |
          terraform init
          
      - name: terraform-apply
        run: |
          if [ "{{.workflow.parameters.terraform_action}}" = "apply" ]; then
            terraform apply -auto-approve tfplan
          elif [ "{{.workflow.parameters.terraform_action}}" = "destroy" ]; then
            terraform destroy -auto-approve
          fi
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"
          
      - name: configure-kubectl
        run: |
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
          kubectl cluster-info
          kubectl get nodes
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"
          
      - name: upload-kubeconfig
        uses: actions/artifactUpload
        with:
          name: kubeconfig
          path: ~/.kube/config

  # Container image build job
  build-images:
    description: "Build and push container images"
    stage: build
    depends_on: [security-scan]
    requirements:
      - model: linux
        os: ubuntu
        memory: 4096
        services:
          - docker
    strategy:
      matrix:
        service: 
          - emailservice
          - checkoutservice
          - recommendationservice
          - frontend
          - paymentservice
          - productcatalogservice
          - cartservice
          - currencyservice
          - shippingservice
          - adservice
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: setup-docker
        run: |
          docker --version
          
      - name: login-to-ecr
        run: |
          aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $(aws sts get-caller-identity --query Account --output text).dkr.ecr.$AWS_REGION.amazonaws.com
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"
          
      - name: build-and-push
        run: |
          SERVICE="{{.cds.build.matrix.service}}"
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REGISTRY="$ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com"
          IMAGE_TAG="{{.git.hash}}"
          
          # Check if custom Dockerfile exists
          if [ -f "src/$SERVICE/Dockerfile" ]; then
            echo "Building custom image for $SERVICE"
            docker build -t $ECR_REGISTRY/$ECR_REPOSITORY-$SERVICE:$IMAGE_TAG src/$SERVICE/
            docker build -t $ECR_REGISTRY/$ECR_REPOSITORY-$SERVICE:latest src/$SERVICE/
            
            # Scan image for vulnerabilities
            trivy image --exit-code 1 --severity HIGH,CRITICAL $ECR_REGISTRY/$ECR_REPOSITORY-$SERVICE:$IMAGE_TAG || true
            
            # Push images
            docker push $ECR_REGISTRY/$ECR_REPOSITORY-$SERVICE:$IMAGE_TAG
            docker push $ECR_REGISTRY/$ECR_REPOSITORY-$SERVICE:latest
            
            echo "Pushed $ECR_REGISTRY/$ECR_REPOSITORY-$SERVICE:$IMAGE_TAG"
          else
            echo "Using pre-built image from gcr.io for $SERVICE"
          fi
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"

  # Application deployment job
  deploy-applications:
    description: "Deploy microservices to EKS cluster"
    stage: deploy-apps
    depends_on: [terraform-apply, build-images]
    requirements:
      - model: linux
        os: ubuntu
        memory: 1024
    conditions:
      - type: parameter
        when: "{{.workflow.parameters.deploy_apps}} == true"
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: download-kubeconfig
        uses: actions/artifactDownload
        with:
          name: kubeconfig
          
      - name: setup-kubectl
        run: |
          mkdir -p ~/.kube
          cp config ~/.kube/config
          kubectl cluster-info
          
      - name: deploy-applications
        run: |
          # Update image tags in deployment if using custom images
          if [ -f "deployment.yml" ]; then
            # Replace image tags with current commit hash
            sed -i "s/:v0.7.0/:{{.git.hash}}/g" deployment.yml
            
            # Apply the deployment
            kubectl apply -f deployment.yml
            
            # Wait for deployments to be ready
            deployments=(
              "emailservice"
              "checkoutservice" 
              "recommendationservice"
              "frontend"
              "paymentservice"
              "productcatalogservice"
              "cartservice"
              "loadgenerator"
              "currencyservice"
              "shippingservice"
              "redis-cart"
              "adservice"
            )
            
            for deployment in "${deployments[@]}"; do
              echo "Waiting for deployment $deployment..."
              kubectl wait --for=condition=available --timeout=300s deployment/$deployment || true
            done
            
            # Get service information
            kubectl get services
            
            # Get LoadBalancer endpoint
            kubectl wait --for=jsonpath='{.status.loadBalancer.ingress}' service/frontend-external --timeout=600s || true
            EXTERNAL_IP=$(kubectl get service frontend-external -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            echo "Application accessible at: http://$EXTERNAL_IP"
            
            # Save endpoint for testing
            echo $EXTERNAL_IP > frontend-endpoint.txt
          else
            echo "deployment.yml not found"
            exit 1
          fi
          
      - name: upload-endpoint
        uses: actions/artifactUpload
        with:
          name: application-endpoint
          path: frontend-endpoint.txt

  # Integration tests job
  integration-tests:
    description: "Run integration tests against deployed application"
    stage: test
    depends_on: [deploy-applications]
    requirements:
      - model: linux
        os: ubuntu
        memory: 1024
    conditions:
      - type: parameter
        when: "{{.workflow.parameters.run_tests}} == true"
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: download-endpoint
        uses: actions/artifactDownload
        with:
          name: application-endpoint
          
      - name: download-kubeconfig
        uses: actions/artifactDownload
        with:
          name: kubeconfig
          
      - name: setup-kubectl
        run: |
          mkdir -p ~/.kube
          cp config ~/.kube/config
          
      - name: health-checks
        run: |
          # Wait for all pods to be ready
          echo "Checking pod status..."
          kubectl get pods --all-namespaces
          
          # Check if all pods are running
          failed_pods=$(kubectl get pods --field-selector=status.phase=Failed --no-headers | wc -l)
          if [ $failed_pods -gt 0 ]; then
            echo "Found $failed_pods failed pods"
            kubectl get pods --field-selector=status.phase=Failed
            exit 1
          fi
          
          # Test frontend accessibility
          if [ -f "frontend-endpoint.txt" ]; then
            EXTERNAL_IP=$(cat frontend-endpoint.txt)
            if [ -n "$EXTERNAL_IP" ]; then
              echo "Testing frontend at: http://$EXTERNAL_IP"
              
              # Wait for endpoint to be accessible
              for i in {1..30}; do
                if curl -f -s http://$EXTERNAL_IP > /dev/null; then
                  echo "Frontend is accessible!"
                  break
                else
                  echo "Attempt $i: Frontend not yet accessible, waiting..."
                  sleep 10
                fi
              done
              
              # Run basic HTTP tests
              curl -f http://$EXTERNAL_IP || exit 1
              echo "Basic health check passed!"
              
              # Test product catalog
              curl -f http://$EXTERNAL_IP/product/OLJCESPC7Z || exit 1
              echo "Product catalog test passed!"
              
            else
              echo "No external IP available for testing"
            fi
          fi
          
      - name: load-tests
        run: |
          if [ -f "frontend-endpoint.txt" ]; then
            EXTERNAL_IP=$(cat frontend-endpoint.txt)
            if [ -n "$EXTERNAL_IP" ]; then
              echo "Running load tests..."
              
              # Simple load test
              for i in {1..50}; do
                curl -s http://$EXTERNAL_IP > /dev/null &
              done
              wait
              
              echo "Load test completed!"
            fi
          fi
          
      - name: performance-tests
        run: |
          # Install Apache Bench
          sudo apt-get update
          sudo apt-get install apache2-utils
          
          if [ -f "frontend-endpoint.txt" ]; then
            EXTERNAL_IP=$(cat frontend-endpoint.txt)
            if [ -n "$EXTERNAL_IP" ]; then
              echo "Running performance tests..."
              
              # Run Apache Bench test
              ab -n 100 -c 10 http://$EXTERNAL_IP/ > performance-report.txt
              cat performance-report.txt
              
              # Check if response time is acceptable (< 2 seconds average)
              avg_time=$(grep "Time per request" performance-report.txt | head -1 | awk '{print $4}')
              if (( $(echo "$avg_time > 2000" | bc -l) )); then
                echo "Performance test failed: Average response time too high ($avg_time ms)"
                exit 1
              fi
              
              echo "Performance test passed!"
            fi
          fi
          
      - name: upload-test-results
        uses: actions/artifactUpload
        with:
          name: test-results
          path: performance-report.txt

  # Monitoring setup job
  setup-monitoring:
    description: "Setup monitoring stack (Prometheus, Grafana)"
    stage: monitoring
    depends_on: [deploy-applications]
    requirements:
      - model: linux
        os: ubuntu
        memory: 2048
    conditions:
      - type: branch
        when: "{{.git.branch}} == 'main'"
      - type: parameter
        when: "{{.workflow.parameters.environment}} == 'production'"
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: download-kubeconfig
        uses: actions/artifactDownload
        with:
          name: kubeconfig
          
      - name: setup-kubectl-helm
        run: |
          mkdir -p ~/.kube
          cp config ~/.kube/config
          kubectl cluster-info
          
      - name: install-monitoring
        run: |
          # Make monitoring script executable
          chmod +x ./monitoring-setup.sh
          
          # Install monitoring stack
          ./monitoring-setup.sh install
          
          # Get Grafana access information
          ./monitoring-setup.sh access > monitoring-access.txt
          cat monitoring-access.txt
          
      - name: upload-monitoring-info
        uses: actions/artifactUpload
        with:
          name: monitoring-access
          path: monitoring-access.txt

  # Backup setup job
  setup-backup:
    description: "Setup backup infrastructure"
    stage: backup
    depends_on: [deploy-applications]
    requirements:
      - model: linux
        os: ubuntu
        memory: 1024
    conditions:
      - type: branch
        when: "{{.git.branch}} == 'main'"
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: download-kubeconfig
        uses: actions/artifactDownload
        with:
          name: kubeconfig
          
      - name: setup-kubectl
        run: |
          mkdir -p ~/.kube
          cp config ~/.kube/config
          
      - name: install-backup
        run: |
          # Make backup script executable
          chmod +x ./backup-dr.sh
          
          # Install backup infrastructure
          ./backup-dr.sh install
          
          # Create initial backup
          ./backup-dr.sh backup "initial-backup-{{.git.hash}}"
          
          # Test backup functionality
          ./backup-dr.sh test
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"

  # Security compliance check
  security-compliance:
    description: "Run security compliance checks on deployed cluster"
    stage: compliance
    depends_on: [deploy-applications]
    requirements:
      - model: linux
        os: ubuntu
        memory: 2048
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: download-kubeconfig
        uses: actions/artifactDownload
        with:
          name: kubeconfig
          
      - name: setup-kubectl
        run: |
          mkdir -p ~/.kube
          cp config ~/.kube/config
          
      - name: security-audit
        run: |
          # Make security script executable
          chmod +x ./security-compliance.sh
          
          # Run security audit
          ./security-compliance.sh audit
          
          # Generate security scorecard
          ./security-compliance.sh scorecard
          
          # Upload security reports
          tar -czf security-reports.tar.gz security-reports/
          
      - name: upload-security-reports
        uses: actions/artifactUpload
        with:
          name: security-compliance-reports
          path: security-reports.tar.gz

  # Cleanup job
  cleanup:
    description: "Cleanup resources (for non-production environments)"
    stage: cleanup
    depends_on: [integration-tests]
    requirements:
      - model: linux
        os: ubuntu
        memory: 1024
    conditions:
      - type: parameter
        when: "{{.workflow.parameters.environment}} != 'production'"
      - type: manual
    steps:
      - name: checkout
        uses: actions/gitClone
        with:
          url: "{{.git.url}}"
          branch: "{{.git.branch}}"
          commit: "{{.git.hash}}"
          
      - name: terraform-destroy
        run: |
          terraform init
          terraform destroy -auto-approve
        env:
          AWS_ACCESS_KEY_ID: "{{.cds.env.AWS_ACCESS_KEY_ID}}"
          AWS_SECRET_ACCESS_KEY: "{{.cds.env.AWS_SECRET_ACCESS_KEY}}"

  # Notification job
  notify:
    description: "Send notifications about pipeline status"
    stage: notify
    depends_on: [integration-tests, setup-monitoring, setup-backup, security-compliance]
    requirements:
      - model: linux
        os: ubuntu
        memory: 512
    always: true
    steps:
      - name: send-slack-notification
        run: |
          # Determine pipeline status
          if [ "{{.cds.status}}" = "Success" ]; then
            COLOR="good"
            STATUS_EMOJI=":white_check_mark:"
            MESSAGE="Pipeline completed successfully!"
          else
            COLOR="danger"
            STATUS_EMOJI=":x:"
            MESSAGE="Pipeline failed!"
          fi
          
          # Send Slack notification
          curl -X POST -H 'Content-type: application/json' \
            --data "{
              \"attachments\": [{
                \"color\": \"$COLOR\",
                \"title\": \"$STATUS_EMOJI EKS Deployment Pipeline\",
                \"text\": \"$MESSAGE\",
                \"fields\": [
                  {\"title\": \"Environment\", \"value\": \"{{.workflow.parameters.environment}}\", \"short\": true},
                  {\"title\": \"Branch\", \"value\": \"{{.git.branch}}\", \"short\": true},
                  {\"title\": \"Commit\", \"value\": \"{{.git.hash}}\", \"short\": true},
                  {\"title\": \"Status\", \"value\": \"{{.cds.status}}\", \"short\": true}
                ]
              }]
            }" \
            "{{.cds.env.SLACK_WEBHOOK_URL}}"

# Hooks for different events
hooks:
  - type: webhook
    config:
      url: "{{.cds.env.WEBHOOK_URL}}"
      method: POST
      headers:
        Content-Type: "application/json"
    on:
      - workflow-started
      - workflow-success
      - workflow-failure

# Pipeline permissions
permissions:
  - permission: read
    users: ["developer-team"]
  - permission: execute
    users: ["devops-team", "admin"]
  - permission: admin
    users: ["admin"]
